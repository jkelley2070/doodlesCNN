{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages \n",
    "\n",
    "* PIL for images\n",
    "* torchvision for pytorch computer vision support \n",
    "* datasets -> loading dataset with huggingface dataset api\n",
    "* matplotlib for showing images\n",
    "* torch and its many packages and modules for nn\n",
    "* tqdm for progress bar when training and testing\n",
    "* numpy for math stuff\n",
    "* ray tune for hyperparameter otpimization\n",
    "* torch summary for model params count\n",
    "* typing for better clarity \n",
    "* CNN storing the cnn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Users/kelley/Desktop/drawAI/.env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install packages\n",
    "!pip -q install accelerate datasets evaluate torchvision Pillow 'transformers[torch]' tqdm ray tensorboardX torchmetrics torchsummary scikit-learn numpy torch matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Subset\n",
    "import matplotlib as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import random\n",
    "from ray import tune\n",
    "from tensorboardX import SummaryWriter\n",
    "from ray.tune.stopper import MaximumIterationStopper, TrialPlateauStopper\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from torchmetrics import AveragePrecision\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from torchsummary import summary\n",
    "from datasets import Dataset, DatasetDict\n",
    "from typing import List, Dict, Any\n",
    "import ray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset infromation \n",
    "* 10% Subset of Google's 50 million quickdraw dataset \n",
    "    * training -> 4.5 million\n",
    "    * validation -> .5 million \n",
    "    * test ->.5 million\n",
    "* link -> https://huggingface.co/datasets/Xenova/quickdraw-small?row=0\n",
    "* 28 x 28 images of drawings \n",
    "* 345 labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mac gpu loading \n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "# loading dataset into huggign face dataset dictionary/object\n",
    "dataset:DatasetDict = load_dataset('Xenova/quickdraw-small')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 batches tested for each, previously generated with random\n",
    "# example\n",
    "# batcha_selected_classes_10  = random.sample(range(0, 344), 10)\n",
    "batcha_selected_classes_10 = [121, 162, 120, 211, 43, 185, 177, 171, 232, 322]\n",
    "batcha_selected_classes_50 = [143, 149, 306, 233, 107, 196, 129, 186, 22, 227, 16, 253, 199, 194, 333, 122, 297, 307, 217, 42, 251, 158, 324, 124, 334, 270, 165, 78, 214, 289, 69, 169, 206, 133, 278, 262, 298, 54, 115, 272, 110, 215, 209, 172, 328, 5, 207, 14, 9, 51]\n",
    "batchb_selected_classes_10 = [223, 60, 237, 51, 234, 94, 53, 161, 300, 320]\n",
    "batchb_selected_classes_50 = [148, 30, 79, 253, 18, 6, 141, 116, 150, 273, 68, 339, 262, 302, 197, 56, 333, 182, 265, 323, 101, 226, 308, 155, 171, 199, 25, 28, 48, 10, 342, 66, 104, 318, 185, 330, 263, 257, 35, 296, 70, 228, 272, 316, 42, 69, 233, 127, 217, 169]\n",
    "batchc_selected_classes_10 = [302, 323, 107, 312, 184, 235, 179, 146, 38, 149]\n",
    "batchc_selected_classes_50 = [248, 32, 60, 128, 290, 77, 49, 282, 95, 176, 193, 72, 189, 226, 100, 107, 304, 308, 14, 287, 35, 250, 111, 297, 291, 112, 62, 168, 136, 11, 323, 327, 239, 88, 159, 120, 257, 240, 24, 16, 148, 160, 40, 96, 155, 53, 280, 36, 64, 151]\n",
    "\n",
    "# pytorch must have labels 0 - x, so using dict to create mapping\n",
    "# i.e 121::0, 162:1, using this mapping later\n",
    "def create_label_mapping(selected_classes: List[int]) -> Dict[int, int]:\n",
    "    return {old_label: new_label for new_label, old_label in enumerate(selected_classes)}\n",
    "\n",
    "# function to create a flag in the dataset to filter based on\n",
    "# there are better ways to do this but trying to use pretrained models later\n",
    "# and want it as flexible as possible\n",
    "def transform_example(example: Dict[str, Any], selected_classes: List[int], label_mapping: Dict[int, int]) -> Dict[str, Any]:\n",
    "    if example['label'] in selected_classes:\n",
    "        return {'image': example['image'], 'label': label_mapping[example['label']], 'is_selected': True}\n",
    "    else:\n",
    "        return {'is_selected': False}\n",
    "\n",
    "\n",
    "# dictorying storing each diction\n",
    "datasets: Dict[str, DatasetDict[str, Dataset]] = {}\n",
    "\n",
    "# applying everything to all 6 batches \n",
    "for batch, selected_classes in [('batcha', batcha_selected_classes_10),\n",
    "                                ('batcha', batcha_selected_classes_50),\n",
    "                                ('batchb', batchb_selected_classes_10),\n",
    "                                ('batchb', batchb_selected_classes_50),\n",
    "                                ('batchc', batchc_selected_classes_10),\n",
    "                                ('batchc', batchc_selected_classes_50)]:\n",
    "    # getting the label mapping\n",
    "    label_mapping:Dict[int, int] = create_label_mapping(selected_classes)\n",
    "    # flagging and mapping labels each class\n",
    "    dataset_with_updated_labels: DatasetDict = dataset.map(lambda x: transform_example(x, selected_classes, label_mapping))\n",
    "    \n",
    "    # filtering classes that are flagged/selected\n",
    "    # very pythonic syntax cuz train, val, test splits \n",
    "    filtered_dataset: Dict[str, Dataset] = {split: ds.filter(lambda x: x['is_selected']) for split, ds in dataset_with_updated_labels.items()}\n",
    "    datasets[f\"{batch}_{len(selected_classes)}\"] = filtered_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline \n",
    "\n",
    "- transforing dataset to tensors\n",
    "- storing everything in a dict \n",
    "- subsetting data based on batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(dataset: DatasetDict) -> Dict[str, torch.Tensor]:\n",
    "    # pytorch preprocess\n",
    "    processor: transforms.Compose = transforms.Compose([\n",
    "        # augment stuff for later to see if it improves performance\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        # transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),  # range of values 0 - 1\n",
    "        transforms.Normalize((0.5,), (0.5,)),  # std .5, mean .5\n",
    "    ])\n",
    "    # convert each image to 3d numpy array then reshape into a (height, width)) tensor\n",
    "    images: List[torch.Tensor] = [processor(np.array(x).reshape(28, 28)) for x in dataset['image']]\n",
    "    # return dictionary containing single 3d tensor storing all images and 1d tensor for labels\n",
    "    return {'image': torch.stack(images), 'label': torch.tensor(dataset['label'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting data \n",
    "Original Data 4.5 Million rows 90/5/5 split\n",
    "Updated \n",
    "\n",
    "- 10 Classes: 100% Train. 100% Validation% 100% Testing\n",
    "\n",
    "- 50 Classes: 30% Train.  60% Validation% 60% Testing\n",
    "\n",
    "- 345 Classes: 25% Train. 50% Validation% 50% Testing\n",
    "\n",
    "- Using pytorch subset to do this!\n",
    "\n",
    "Setting up dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BatchA 10 classes\n",
    "transformed_dataset_batcha_10 = {split: ds.with_transform(transform) for split, ds in datasets['batcha_10'].items()}\n",
    "\n",
    "subset_ratio = 1\n",
    "train_subset_size_batcha_10 = int(subset_ratio * len(transformed_dataset_batcha_10['train']))\n",
    "subset_train_dataset_batcha_10 = Subset(transformed_dataset_batcha_10['train'], range(train_subset_size_batcha_10))\n",
    "\n",
    "subset_ratio = 1\n",
    "val_subset_size_batcha_10 = int(subset_ratio * len(transformed_dataset_batcha_10['valid']))\n",
    "subset_validation_dataset_batcha_10 = Subset(transformed_dataset_batcha_10['valid'], range(val_subset_size_batcha_10))\n",
    "\n",
    "subset_ratio = 1\n",
    "test_subset_size_batcha_10 = int(subset_ratio * len(transformed_dataset_batcha_10['test']))\n",
    "subset_test_dataset_batcha_10 = Subset(transformed_dataset_batcha_10['test'], range(test_subset_size_batcha_10))\n",
    "\n",
    "train_loader_batcha_10 = DataLoader(subset_train_dataset_batcha_10, batch_size=16, shuffle=True)\n",
    "validation_loader_batcha_10 = DataLoader(subset_validation_dataset_batcha_10, batch_size=16, shuffle=False)\n",
    "test_loader_batcha_10 = DataLoader(subset_test_dataset_batcha_10, batch_size=16, shuffle=False)\n",
    "\n",
    "# BatchB 10 classes\n",
    "transformed_dataset_batchb_10 = {split: ds.with_transform(transform) for split, ds in datasets['batchb_10'].items()}\n",
    "\n",
    "subset_ratio = 1\n",
    "train_subset_size_batchb_10 = int(subset_ratio * len(transformed_dataset_batchb_10['train']))\n",
    "subset_train_dataset_batchb_10 = Subset(transformed_dataset_batchb_10['train'], range(train_subset_size_batchb_10))\n",
    "\n",
    "subset_ratio = 1\n",
    "val_subset_size_batchb_10 = int(subset_ratio * len(transformed_dataset_batchb_10['valid']))\n",
    "subset_validation_dataset_batchb_10 = Subset(transformed_dataset_batchb_10['valid'], range(val_subset_size_batchb_10))\n",
    "\n",
    "subset_ratio = 1\n",
    "test_subset_size_batchb_10 = int(subset_ratio * len(transformed_dataset_batchb_10['test']))\n",
    "subset_test_dataset_batchb_10 = Subset(transformed_dataset_batchb_10['test'], range(test_subset_size_batchb_10))\n",
    "\n",
    "train_loader_batchb_10 = DataLoader(subset_train_dataset_batchb_10, batch_size=16, shuffle=True)\n",
    "validation_loader_batchb_10 = DataLoader(subset_validation_dataset_batchb_10, batch_size=16, shuffle=False)\n",
    "test_loader_batchb_10 = DataLoader(subset_test_dataset_batchb_10, batch_size=16, shuffle=False)\n",
    "\n",
    "# BatchC 10 classes\n",
    "transformed_dataset_batchc_10 = {split: ds.with_transform(transform) for split, ds in datasets['batchc_10'].items()}\n",
    "\n",
    "subset_ratio = 1\n",
    "train_subset_size_batchc_10 = int(subset_ratio * len(transformed_dataset_batchc_10['train']))\n",
    "subset_train_dataset_batchc_10 = Subset(transformed_dataset_batchc_10['train'], range(train_subset_size_batchc_10))\n",
    "\n",
    "subset_ratio = 1\n",
    "val_subset_size_batchc_10 = int(subset_ratio * len(transformed_dataset_batchc_10['valid']))\n",
    "subset_validation_dataset_batchc_10 = Subset(transformed_dataset_batchc_10['valid'], range(val_subset_size_batchc_10))\n",
    "\n",
    "subset_ratio = 1\n",
    "test_subset_size_batchc_10 = int(subset_ratio * len(transformed_dataset_batchc_10['test']))\n",
    "subset_test_dataset_batchc_10 = Subset(transformed_dataset_batchc_10['test'], range(test_subset_size_batchc_10))\n",
    "\n",
    "train_loader_batchc_10 = DataLoader(subset_train_dataset_batchc_10, batch_size=16, shuffle=True)\n",
    "validation_loader_batchc_10 = DataLoader(subset_validation_dataset_batchc_10, batch_size=16, shuffle=False)\n",
    "test_loader_batchc_10 = DataLoader(subset_test_dataset_batchc_10, batch_size=16, shuffle=False)\n",
    "\n",
    "# BatchA 50 classes\n",
    "transformed_dataset_batcha_50 = {split: ds.with_transform(transform) for split, ds in datasets['batcha_50'].items()}\n",
    "\n",
    "subset_ratio = 0.6\n",
    "train_subset_size_batcha_50 = int(subset_ratio * len(transformed_dataset_batcha_50['train']))\n",
    "subset_train_dataset_batcha_50 = Subset(transformed_dataset_batcha_50['train'], range(train_subset_size_batcha_50))\n",
    "\n",
    "subset_ratio = 0.3\n",
    "val_subset_size_batcha_50 = int(subset_ratio * len(transformed_dataset_batcha_50['valid']))\n",
    "subset_validation_dataset_batcha_50 = Subset(transformed_dataset_batcha_50['valid'], range(val_subset_size_batcha_50))\n",
    "\n",
    "subset_ratio = 0.3\n",
    "test_subset_size_batcha_50 = int(subset_ratio * len(transformed_dataset_batcha_50['test']))\n",
    "subset_test_dataset_batcha_50 = Subset(transformed_dataset_batcha_50['test'], range(test_subset_size_batcha_50))\n",
    "\n",
    "train_loader_batcha_50 = DataLoader(subset_train_dataset_batcha_50, batch_size=16, shuffle=True)\n",
    "validation_loader_batcha_50 = DataLoader(subset_validation_dataset_batcha_50, batch_size=16, shuffle=False)\n",
    "test_loader_batcha_50 = DataLoader(subset_test_dataset_batcha_50, batch_size=16, shuffle=False)\n",
    "\n",
    "# BatchB 50 classes\n",
    "transformed_dataset_batchb_50 = {split: ds.with_transform(transform) for split, ds in datasets['batchb_50'].items()}\n",
    "\n",
    "subset_ratio = 0.6\n",
    "train_subset_size_batchb_50 = int(subset_ratio * len(transformed_dataset_batchb_50['train']))\n",
    "subset_train_dataset_batchb_50 = Subset(transformed_dataset_batchb_50['train'], range(train_subset_size_batchb_50))\n",
    "\n",
    "subset_ratio = 0.3\n",
    "val_subset_size_batchb_50 = int(subset_ratio * len(transformed_dataset_batchb_50['valid']))\n",
    "subset_validation_dataset_batchb_50 = Subset(transformed_dataset_batchb_50['valid'], range(val_subset_size_batchb_50))\n",
    "\n",
    "subset_ratio = 0.3\n",
    "test_subset_size_batchb_50 = int(subset_ratio * len(transformed_dataset_batchb_50['test']))\n",
    "subset_test_dataset_batchb_50 = Subset(transformed_dataset_batchb_50['test'], range(test_subset_size_batchb_50))\n",
    "\n",
    "train_loader_batchb_50 = DataLoader(subset_train_dataset_batchb_50, batch_size=16, shuffle=True)\n",
    "validation_loader_batchb_50 = DataLoader(subset_validation_dataset_batchb_50, batch_size=16, shuffle=False)\n",
    "test_loader_batchb_50 = DataLoader(subset_test_dataset_batchb_50, batch_size=16, shuffle=False)\n",
    "\n",
    "# BatchC 50 classes\n",
    "transformed_dataset_batchc_50 = {split: ds.with_transform(transform) for split, ds in datasets['batchc_50'].items()}\n",
    "\n",
    "subset_ratio = 0.6\n",
    "train_subset_size_batchc_50 = int(subset_ratio * len(transformed_dataset_batchc_50['train']))\n",
    "subset_train_dataset_batchc_50 = Subset(transformed_dataset_batchc_50['train'], range(train_subset_size_batchc_50))\n",
    "\n",
    "subset_ratio = 0.3\n",
    "val_subset_size_batchc_50 = int(subset_ratio * len(transformed_dataset_batchc_50['valid']))\n",
    "subset_validation_dataset_batchc_50 = Subset(transformed_dataset_batchc_50['valid'], range(val_subset_size_batchc_50))\n",
    "\n",
    "subset_ratio = 0.3\n",
    "test_subset_size_batchc_50 = int(subset_ratio * len(transformed_dataset_batchc_50['test']))\n",
    "subset_test_dataset_batchc_50 = Subset(transformed_dataset_batchc_50['test'], range(test_subset_size_batchc_50))\n",
    "\n",
    "train_loader_batchc_50 = DataLoader(subset_train_dataset_batchc_50, batch_size=8, shuffle=True)\n",
    "validation_loader_batchc_50 = DataLoader(subset_validation_dataset_batchc_50, batch_size=8, shuffle=False)\n",
    "test_loader_batchc_50 = DataLoader(subset_test_dataset_batchc_50, batch_size=8, shuffle=False)\n",
    "\n",
    "transformed_dataset = {split: ds.with_transform(transform) for split, ds in dataset.items()}\n",
    "# subset selected\n",
    "train_subset_size_345 = int(0.25 * len(transformed_dataset['train']))\n",
    "subset_train_dataset_345 = Subset(transformed_dataset['train'], range(train_subset_size_345))\n",
    "\n",
    "val_subset_size_345 = int(0.50 * len(transformed_dataset['valid']))\n",
    "subset_validation_dataset_345 = Subset(transformed_dataset['valid'], range(val_subset_size_345))\n",
    "\n",
    "test_subset_size_345 = int(0.50 * len(transformed_dataset['test']))\n",
    "subset_test_dataset_345 = Subset(transformed_dataset['test'], range(test_subset_size_345))\n",
    "\n",
    "train_loader_345 = DataLoader(subset_train_dataset_345, batch_size=16, shuffle=True)\n",
    "validation_loader_345 = DataLoader(subset_validation_dataset_345, batch_size=16, shuffle=False)\n",
    "test_loader_345 = DataLoader(subset_test_dataset_345, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "- Models for each batch 7 models total!\n",
    "- 9 CNN models written in CNN_models.py\n",
    "    - CNN1 - A simple convolutional neural network model.\n",
    "    - CNN2 - An improved convolutional neural network model with additional layers and modifications.\n",
    "    - CNN3 - A version with more filters than the base model.\n",
    "    - CNN4 - A version with additional dense layers.\n",
    "    - CNN5 - A version with more filters.\n",
    "    - CNN6 - A version with double convolutional blocks.\n",
    "    - bestCNN - A version with hyperparameter optimization using Ray Tune.\n",
    "    - CNN8 - A version with residual blocks based on the Dive into Deep Learning textbook.\n",
    "    - CNN9 - A version with more layers of residual blocks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             288\n",
      "       BatchNorm2d-2           [-1, 32, 28, 28]              64\n",
      "              ReLU-3           [-1, 32, 28, 28]               0\n",
      "           Dropout-4           [-1, 32, 28, 28]               0\n",
      "            Conv2d-5           [-1, 32, 28, 28]           9,216\n",
      "       BatchNorm2d-6           [-1, 32, 28, 28]              64\n",
      "              ReLU-7           [-1, 32, 28, 28]               0\n",
      "           Dropout-8           [-1, 32, 28, 28]               0\n",
      "         MaxPool2d-9           [-1, 32, 14, 14]               0\n",
      "           Conv2d-10           [-1, 64, 14, 14]          18,432\n",
      "      BatchNorm2d-11           [-1, 64, 14, 14]             128\n",
      "             ReLU-12           [-1, 64, 14, 14]               0\n",
      "          Dropout-13           [-1, 64, 14, 14]               0\n",
      "           Conv2d-14           [-1, 64, 14, 14]          36,864\n",
      "      BatchNorm2d-15           [-1, 64, 14, 14]             128\n",
      "             ReLU-16           [-1, 64, 14, 14]               0\n",
      "          Dropout-17           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-18             [-1, 64, 7, 7]               0\n",
      "           Conv2d-19            [-1, 128, 7, 7]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 7, 7]             256\n",
      "             ReLU-21            [-1, 128, 7, 7]               0\n",
      "          Dropout-22            [-1, 128, 7, 7]               0\n",
      "           Conv2d-23            [-1, 128, 7, 7]         147,456\n",
      "      BatchNorm2d-24            [-1, 128, 7, 7]             256\n",
      "             ReLU-25            [-1, 128, 7, 7]               0\n",
      "          Dropout-26            [-1, 128, 7, 7]               0\n",
      "        MaxPool2d-27            [-1, 128, 3, 3]               0\n",
      "          Dropout-28            [-1, 128, 3, 3]               0\n",
      "          Flatten-29                 [-1, 1152]               0\n",
      "           Linear-30                  [-1, 256]         295,168\n",
      "          Sigmoid-31                  [-1, 256]               0\n",
      "           Linear-32                  [-1, 345]          88,665\n",
      "================================================================\n",
      "Total params: 670,713\n",
      "Trainable params: 670,713\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.78\n",
      "Params size (MB): 2.56\n",
      "Estimated Total Size (MB): 5.35\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bestCNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout3): Dropout(p=0.1, inplace=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=1152, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=50, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       "  (dropout4): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from CNN_models import bestCNN\n",
    "model_full = bestCNN(345)\n",
    "print(summary(model_full, (1, 28, 28)))\n",
    "model_full.to(device)\n",
    "\n",
    "model_batcha_10 = bestCNN(10)\n",
    "model_batcha_10.to(device)\n",
    "\n",
    "model_batchb_10 = bestCNN(10)\n",
    "model_batchb_10.to(device)\n",
    "\n",
    "model_batchc_10 = bestCNN(10)\n",
    "model_batchc_10.to(device)\n",
    "\n",
    "model_batcha_50 = bestCNN(50)\n",
    "model_batcha_50.to(device)\n",
    "\n",
    "model_batchb_50 = bestCNN(50)\n",
    "model_batchb_50.to(device)\n",
    "\n",
    "model_batchc_50 = bestCNN(50)\n",
    "model_batchc_50.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the model \n",
    "- creating to handle training and so it's flexible for all 7 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, validation_loader, criterion, optimizer, device, num_epochs, writer_name, save_folder):\n",
    "    # initialize tensorboard\n",
    "    writer = SummaryWriter(writer_name)\n",
    "    \n",
    "    # training/eval loop\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n",
    "        \n",
    "        # train mode\n",
    "        model.train()\n",
    "        \n",
    "        # process batches\n",
    "        for batch in progress_bar:\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            # forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_top1 = 0\n",
    "        correct_top3 = 0\n",
    "        total = 0\n",
    "        preds_list = []\n",
    "        labels_list = []\n",
    "        \n",
    "        # validation loop\n",
    "        with torch.no_grad():\n",
    "            for batch in validation_loader:\n",
    "                images = batch['image'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                # model predictions\n",
    "                preds = model(images)\n",
    "                loss = criterion(preds, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # top-1 and top-3 accuracy\n",
    "                _, predicted_top1 = torch.max(preds.data, 1)\n",
    "                _, predicted_top3 = torch.topk(preds.data, 3, dim=1)\n",
    "                total += labels.size(0)\n",
    "                preds_list.append(preds)\n",
    "                labels_list.append(labels)\n",
    "                \n",
    "                # update correct guesses\n",
    "                correct_top1 += (predicted_top1 == labels).sum().item()\n",
    "                correct_top3 += (predicted_top3 == labels.unsqueeze(1)).any(dim=1).sum().item()\n",
    "        \n",
    "        preds_tensor = torch.cat(preds_list, dim=0)\n",
    "        labels_tensor = torch.cat(labels_list, dim=0)\n",
    "        \n",
    "        # final stats\n",
    "        val_loss /= len(validation_loader)\n",
    "        val_accuracy_top1 = correct_top1 / total\n",
    "        val_accuracy_top3 = correct_top3 / total\n",
    "        \n",
    "        # additional metrics\n",
    "        preds_top1 = torch.argmax(preds_tensor, dim=1).cpu().numpy()\n",
    "        labels_numpy = labels_tensor.cpu().numpy()\n",
    "        f1 = f1_score(labels_numpy, preds_top1, average='weighted')\n",
    "        precision = precision_score(labels_numpy, preds_top1, average='weighted')\n",
    "        recall = recall_score(labels_numpy, preds_top1, average='weighted')\n",
    "        \n",
    "        # log to tensorboard\n",
    "        writer.add_scalar('Train Loss', epoch_loss, epoch)\n",
    "        writer.add_scalar('Val Loss', val_loss, epoch)\n",
    "        writer.add_scalar('Val AccuracyTop1', val_accuracy_top1, epoch)\n",
    "        writer.add_scalar('Val AccuracyTop3', val_accuracy_top3, epoch)\n",
    "        writer.add_scalar('F1 Score', f1, epoch)\n",
    "        writer.add_scalar('Precision', precision, epoch)\n",
    "        writer.add_scalar('Recall', recall, epoch)\n",
    "        \n",
    "        # print stats\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, '\n",
    "              f'Val Accuracy Top1: {val_accuracy_top1:.4f}, Val Accuracy Top3: {val_accuracy_top3:.4f}, '\n",
    "              f'F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "    \n",
    "    # save model\n",
    "    save_path = f\"{save_folder}\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizers \n",
    "optimizer_batcha_10 = torch.optim.Adam(model_batcha_10.parameters(), lr=0.001)\n",
    "optimizer_batchb_10 = torch.optim.Adam(model_batchb_10.parameters(), lr=0.001)\n",
    "optimizer_batchc_10 = torch.optim.Adam(model_batchc_10.parameters(), lr=0.001)\n",
    "optimizer_batcha_50 = torch.optim.Adam(model_batcha_50.parameters(), lr=0.001)\n",
    "optimizer_batchb_50 = torch.optim.Adam(model_batchb_50.parameters(), lr=0.001)\n",
    "optimizer_batchc_50 = torch.optim.Adam(model_batchc_50.parameters(), lr=0.001)\n",
    "optimizer_full= torch.optim.Adam(model_full.parameters(), lr=0.001)\n",
    "\n",
    "# training each model\n",
    "train_model(model_batcha_10, train_loader_batcha_10, validation_loader_batcha_10, criterion, optimizer_batcha_10, device, num_epochs=3, writer_name='training_data/batcha_10', save_folder = 'weights/batcha_10')\n",
    "\n",
    "train_model(model_batchb_10, train_loader_batchb_10, validation_loader_batchb_10, criterion, optimizer_batchb_10, device, num_epochs=5, writer_name='training_data/batchb_10', save_folder = 'weights/batchb_10')\n",
    "\n",
    "train_model(model_batchc_10, train_loader_batchc_10, validation_loader_batchc_10, criterion, optimizer_batchc_10, device, num_epochs=5, writer_name='training_data/batchc_10', save_folder = 'weights/batchc_10')\n",
    "\n",
    "train_model(model_batcha_50, train_loader_batcha_50, validation_loader_batcha_50, criterion, optimizer_batcha_50, device, num_epochs=5, writer_name='training_data/batcha_50', save_folder = 'weights/batcha_50')\n",
    "\n",
    "train_model(model_batchb_50, train_loader_batchb_50, validation_loader_batchb_50, criterion, optimizer_batchb_50, device, num_epochs=5, writer_name='training_data/batchb_50', save_folder = 'weights/batchb_50')\n",
    "\n",
    "train_model(model_batchc_50, train_loader_batchc_50, validation_loader_batchc_50, criterion, optimizer_batchc_50, device, num_epochs=5, writer_name='training_data/batchc_50', save_folder = 'weights/batchc_50')\n",
    "\n",
    "train_model(model_full, train_loader_345, validation_loader_345, criterion, optimizer_full, device, num_epochs=5, writer_name='training_data/', save_folder = 'weights/345')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparamter tuning with raytune!\n",
    "- raytune will parallize the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuneCNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(TuneCNN, self).__init__()\n",
    "\n",
    "        # cnn block 1\n",
    "        self.conv1 = nn.Conv2d(1, config[\"channels_1\"], kernel_size=config[\"kernal\"], padding='same', bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(config[\"channels_1\"])\n",
    "        self.conv2 = nn.Conv2d(config[\"channels_1\"], config[\"channels_1\"], kernel_size=config[\"kernal\"], padding='same', bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(config[\"channels_1\"])\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.dropout1 = nn.Dropout(config[\"dropout\"])\n",
    "\n",
    "        # cnn block 2\n",
    "        self.conv3 = nn.Conv2d(config[\"channels_1\"], config[\"channels_2\"], kernel_size=config[\"kernal\"], padding='same', bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(config[\"channels_2\"])\n",
    "        self.conv4 = nn.Conv2d(config[\"channels_2\"], config[\"channels_2\"], kernel_size=config[\"kernal\"], padding='same', bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(config[\"channels_2\"])\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.dropout2 = nn.Dropout(config[\"dropout\"])\n",
    "\n",
    "        # cnn block 3\n",
    "        self.conv5 = nn.Conv2d(config[\"channels_2\"], config[\"channels_3\"], kernel_size=config[\"kernal\"], padding='same', bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(config[\"channels_3\"])\n",
    "        self.conv6 = nn.Conv2d(config[\"channels_3\"], config[\"channels_3\"], kernel_size=config[\"kernal\"], padding='same', bias=False)\n",
    "        self.bn6 = nn.BatchNorm2d(config[\"channels_3\"])\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.dropout3 = nn.Dropout(config[\"dropout\"])\n",
    "\n",
    "        # calculate output size after pooling layers\n",
    "        input_size = 28\n",
    "        output_size = input_size // 2  # after first pooling layer\n",
    "        output_size //= 2  # after second pooling layer\n",
    "        output_size //= 2  # after third pooling layer\n",
    "\n",
    "        # fully connected layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(config[\"channels_3\"] * output_size * output_size, config[\"hidden\"])\n",
    "        self.fc2 = nn.Linear(config[\"hidden\"], config[\"hidden\"])\n",
    "        self.fc3 = nn.Linear(config[\"hidden\"], 10)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        if config[\"activation\"] == \"ReLU\":\n",
    "            self.tanh = nn.ReLU()\n",
    "        elif config[\"activation\"] == \"Sigmoid\":\n",
    "            self.tanh = nn.Sigmoid()\n",
    "        else:\n",
    "            self.tanh = nn.Tanh()\n",
    "        self.dropout4 = nn.Dropout(config[\"dropout\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu(self.bn5(self.conv5(x)))\n",
    "        x = self.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.tanh(self.fc1(x))\n",
    "        x = self.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating configuration dictionary!\n",
    "config = {\n",
    "    \"channels_1\": 32,\n",
    "    \"channels_2\": 64,\n",
    "    \"channels_3\": 128,\n",
    "    \"kernal\": tune.choice([3, 5]),\n",
    "    \"dropout\": tune.uniform(0.1, 0.5),\n",
    "    \"hidden\": 256,\n",
    "    \"activation\": tune.choice([\"ReLU\", \"Sigmoid\", \"Tanh\"]),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "}\n",
    "\n",
    "# two funcitons necessary to prevent rewritting calling\n",
    "# calling original training function\n",
    "def train_model_new(config, model, train_loader, validation_loader, criterion, device, num_epochs, writer_name, save_folder):\n",
    "    # create the optimizer based on the configuration\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    # call the original train_model function with the configured optimizer\n",
    "    train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        validation_loader=validation_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        num_epochs=num_epochs,\n",
    "        writer_name=writer_name,\n",
    "        save_folder=save_folder\n",
    "    )\n",
    "\n",
    "def tune_model(config):\n",
    "    # create the model based on the configuration\n",
    "    model = TuneCNN(config)\n",
    "    model.to(device)\n",
    "\n",
    "    # call the train_model function with the configured model and other arguments\n",
    "    train_model_new(\n",
    "        config=config,\n",
    "        model=model_batcha_10,\n",
    "        train_loader=train_loader_batcha_10,\n",
    "        validation_loader=validation_loader_batcha_10,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        num_epochs=3,\n",
    "        writer_name='training_data/batcha_10',\n",
    "        save_folder='weights/batcha_10'\n",
    "    )\n",
    "\n",
    "analysis = tune.run(\n",
    "    tune_model,\n",
    "    config=config,\n",
    "    num_samples=10,\n",
    "    resources_per_trial={\"cpu\": 2},\n",
    ")\n",
    "\n",
    "best_config = analysis.get_best_config(metric=\"accuracy\", mode=\"max\")\n",
    "print(\"Best configuration: \", best_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
